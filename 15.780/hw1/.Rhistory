age = c(23, "24", 27, 900, 31)
df = data.frame(students, grade, age)
class(df$students)
class(df$grade)
class(df$age)
df$age
as.numeric(df$age)
df$age = as.numeric(df$age)
df$age > 150
sum(df$grade < 0 | df$grade > 100)
library(editrules)
install.packages('editrules')
library(editrules)
E = editset(c("grade < 0", "age > 150"))
V = violatedEdits(E, df)
E
E[1]
#' It tells us, for each row, which rules were violated...
V
#' So we can check, say, how many rows violated each rule...
V[,"num1"] | V[,"num2"] | V[,"num3"]
students = c("John", "Paul", "Ringo", "George", "Ravi")
grade = c(89, 92, NA, 86, NA)
age = c(23, 24, 27, NA, 31)
df = data.frame(students, grade, age)
View(df)
View(df)
mean(df$grade)
mean(df$grade, na.rm = T)
is.na(df)
!is.na(df$age)
sum(is.na(df$grade))
mean(is.na(df$age))
newdf = df[!is.na(df$age),]
newdf
#' Also useful: `complete.cases()` returns T/F for the rows which
#' contain an NA in any column.
complete.cases(df)
#' Or `na.omit()` which filters the dataframe to remove rows with NAs
na.omit(df)
#' The `data` function  loads
data(abalone, package = "PivotalR")
install.packages('PivotalR')
#' The `data` function  loads
data(abalone, package = "PivotalR")
force(abalone)
#' I'm going to remove some columns to make it slightly easier to
#' look at. I'll also save a copy of the full data for later.
abalone = abalone[,-c(1,8,9)]
original = abalone
#' The `sample()` function allows us to pick random numbers from
#' a sequence:
sample(1:100, 5)
set.seed(80)       # Used to get the same random numbers
abalone$length[sample(1:nrow(abalone), 42)] = NA
abalone$diameter[sample(1:nrow(abalone), 100)] = NA
View(abalone)
View(abalone)
sum(is.na(abalone$length))
#' The `md.pattern()` function from `mice` is nice for checking
#' the overall presence of NAs:
library(mice)
install.packages('mice')
md.pattern(abalone)
mice.pattern(abalone)
md.pattern(abalone)
md.pattern(abalone)
#' The `md.pattern()` function from `mice` is nice for checking
#' the overall presence of NAs:
library(mice)
md.pattern(abalone)
dev.off() # Clear plot
#' One way to deal with NAs is to replace them with the mean/median
#' of the column. The `impute()` function from `Hmisc` can help us
#' with this:
library(Hmisc)
install.packages('Hmisc')
impute(abalone$length, mean)
#' One way to deal with NAs is to replace them with the mean/median
#' of the column. The `impute()` function from `Hmisc` can help us
#' with this:
library(Hmisc)
impute(abalone$length, mean)
impute(abalone$diameter, median)
#' In real life, we don't know if this imputation is any good.
#' Here, we know the original data so we can check! Let's learn
#' how to create a function to calculate MAPE:
MAPE = function(actual, imputed) {
percent_errors = abs(actual - imputed) / abs(actual)
return(mean(percent_errors))
}
#' Let's use the function to compute MAPE of our imputation.
org   = original$length               # The uncorrupted data
imp   = impute(abalone$length, mean)  # My imputation
miss  = is.na(abalone$length)         # T/F which elements were NA
MAPE(org[miss], imp[miss])
miss  = is.na(abalone$length)         # T/F which elements were NA
is.na(abalone$length)
original$length
knnOut$length
original$length
is.na(abalone$length)
org[miss]
imp[miss]
#' A MAPE of 30% average error is pretty bad? Can anything do better?
#' The `DMwR` package allows us to do kNN imputation. We will impute
#' length based on height and diameter:
knnOut = knnImputation(abalone[,c("length",
"height",
"diameter",
"shucked")],
k = 10)
org   = original$length               # The uncorrupted data
imp   = knnOut$length                 # My imputation
miss  = is.na(abalone$length)         # T/F which elements were NA
MAPE(org[miss], imp[miss])
#' We'll use the abalone dataset to work through some examples.
#' Reload it:
data(abalone, package = "PivotalR")
#' UNIVARIATE
#' We can look at a histogram with `hist()`
hist(abalone$length, breaks=10, xlab = "Length")
hist(abalone$height, breaks=30, xlab = "Height")
#' We can also look at `boxplot()` which does the IQR outlier
#' calculation for us:
boxplot(abalone$height, horizontal = TRUE, xlab = "Height")
#' BIVARIATE
#' If we want to account for a categorical variable, side-by-side
#' `boxplot()` are good. We use a *formula* (the ~ notation), with
#' the continuous vector on the left and categorical groups on the
#' right:
boxplot(abalone$shucked ~ abalone$sex, xlab = "Sex", ylab = "Shucked weight")
#' If we want to account for a continuous variable, we can use
#' a scatter plot:
plot(abalone$height, abalone$length, xlab="Height", ylab="Length",
xlim=c(0, 0.27))
#' MULTIVARIATE
#' We can calculate cook's distance by running a regression with
#' any variable's we want (see Recitation 2) and using the
#' `cooks.distance()` function:
linreg = lm(shucked ~ length + height + diameter, data = abalone)
cd = cooks.distance(linreg) # The influence of each point in the data
plot(cd, ylab ="Cook's distance")
#' We can use the `which.max()` function from last time to find
#' the point with the most influence:
cd[which.max(cd)]
abalone[which.max(cd),]
which.max(cd)
cd
linreg
install.packages('mlbench')
library(mlbench)
# PROBLEM 1 MISSING VALUES
data(Glass , package = "mlbench")
View(Glass)
View(Glass)
library(Hmisc)
# 2) impute the variable Si with its mean value
impute(Glass$Si, mean)
org = c(1, 2, 3, 4)
new = c(0, 2, 4 ,4)
org - new
diff - org - new
diff = org - new
diff^2
(org - new)^2
# PROBLEM 1 MISSING VALUES
data(Glass , package = "mlbench")
original = Glass
original == Glass
set.seed(80)
Glass$Si[sample(1:nrow(Glass), 30)] = NA
Glass$K[sample(1:nrow(Glass), 30)] = NA
original == Glass
# 2) impute the variable Si with its mean value
impute(Glass$Si, mean)
# 3) Impute the variable Si with median
#    report the MAE, MSE and MAPE values to evaluate the accuracy of this imputation
impute(Glass$Si, median)
# PROBLEM 1 MISSING VALUES
data(Glass , package = "mlbench")
set.seed(80)
Glass$Si[sample(1:nrow(Glass), 30)] = NA
Glass$K[sample(1:nrow(Glass), 30)] = NA
# 3) Impute the variable Si with median
#    report the MAE, MSE and MAPE values to evaluate the accuracy of this imputation
impute(Glass$Si, median)
View(Glass)
View(Glass)
# 3) Impute the variable Si with median
#    report the MAE, MSE and MAPE values to evaluate the accuracy of this imputation
imp = impute(Glass$Si, median)
org = original$Si
MAE(org[miss], imp[miss])
abs_errors = abs(actual - imputed)
MAE = function(actual, imputed) {
abs_errors = abs(actual - imputed)
return(mean(abs_errors))
}
MSE = function(actual, imputed) {
sq_errors = (actual - imputed)^2
}
MAPE = function(actual, imputed) {
percent_errors = abs(actual - imputed) / abs(actual)
return(mean(percent_errors))
}
MAE(org[miss], imp[miss])
# 3) Impute the variable Si with median
#    report the MAE, MSE and MAPE values to evaluate the accuracy of this imputation
imp = impute(Glass$Si, median)
org = original$Si
# find the cells where we introduced NAs
miss  = is.na(Glass$Si)
MAE(org[miss], imp[miss])
MSE(org[miss], imp[miss])
MSE = function(actual, imputed) {
sq_errors = (actual - imputed)^2
return(mean(sq_errors))
}
MAE(org[miss], imp[miss])
MSE(org[miss], imp[miss])
MAPE(org[miss], imp[miss])
# PROBLEM 1 MISSING VALUES
data(Glass , package = "mlbench")
# keep a copy of the original data
original = Glass
set.seed(80)
Glass$Si[sample(1:nrow(Glass), 30)] = NA
Glass$K[sample(1:nrow(Glass), 30)] = NA
imp = impute(Glass$Si, median)
org = original$Si
# find the cells where we introduced NAs
miss  = is.na(Glass$Si)
MAE(org[miss], imp[miss])
MSE(org[miss], imp[miss])
MAPE(org[miss], imp[miss])
library(DMwR)
# 4) Impute the variable Si using KNN using the 5 nearest neighbours
#    report the MAE, MSE and MAPE values to evaluate the accuracy of this imputation.
org = original$Si
imp = knnImputation(Glass$Si, k = 5)
imp = knnImputation(Glass[,c("Si")], k = 5)
#' A MAPE of 30% average error is pretty bad? Can anything do better?
#' The `DMwR` package allows us to do kNN imputation. We will impute
#' length based on height and diameter:
knnOut = knnImputation(abalone[,c("length",
"height",
"diameter",
"shucked")],
k = 10)
imp = knnImputation(Glass, k = 5)
knnOut = knnImputation(Glass, k = 5)
imp = knnOut$Si
miss  = is.na(Glass$Si)
MAE(org[miss], imp[miss])
MSE(org[miss], imp[miss])
MAPE(org[miss], imp[miss])
library(editrules)
# 1) Load iris.csv, use the str() function to get a first look at the data
#    check if any columns need to be coerced into a different data type
iris = read.csv('iris.csv')
setwd("Users/lydiayu/Dropbox (MIT)/Senior/15.780/hw1")
setwd("~/Dropbox (MIT)/Senior/15.780/hw1")
# 1) Load iris.csv, use the str() function to get a first look at the data
#    check if any columns need to be coerced into a different data type
iris = read.csv('iris.csv')
View(iris)
View(iris)
str(iris)
# 2) Make a histogram for each numeric column
hist(iris$Sepal.Length, breaks=30, xlab = "Sepal Length")
hist(iris$Sepal.Width, breaks=30, xlab = "Sepal Width")
hist(iris$Petal.Length, breaks=30, xlab = "Petal Length")
hist(iris$Petal.Width, breaks=30, xlab = "Petal Width")
# 1) Load iris.csv, use the str() function to get a first look at the data
#    check if any columns need to be coerced into a different data type
iris = read.csv('iris.csv')
# 2) Make a histogram for each numeric column
hist(iris$Sepal.Length, breaks=30, xlab = "Sepal Length")
hist(iris$Sepal.Width, breaks=30, xlab = "Sepal Width")
hist(iris$Petal.Length, breaks=30, xlab = "Petal Length")
hist(iris$Petal.Width, breaks=30, xlab = "Petal Width")
editset(c("Sepal.width > 10, Petal.Length < 0"))
editset(c("Sepal.width > 10", "Petal.Length < 0"))
# 3) create a simple ruleset that contains the rules that the columns of the dataframe should obey
# Sepal.width should not have values over 10, Petal.Length cannot be negative:
E = editset(c("Sepal.Width > 10", "Petal.Length < 0"))
V = violatedEdits(E, iris)
V
V[,"num1"]
V['num1']
v
V
V[,'num1']
# 4) number of observations that violate each of the rules
# V[, 'num1'] gives which rows violated the first rule (Sepal.Width > 10)
sum(V[,"num1"])
# 4) number of observations that violate each of the rules
# V[, 'num1'] gives which rows violated the first rule (Sepal.Width > 10)
sum(!V[,"num1"])
#  V[, 'num2'] gives which rows violated Petal.Length < 0 (False if violated)
sum(!V[, 'num2'])
# 5) Filter iris to contain only observations that do not violate any of the rules
iris = subset(iris, V)
V.head
V.head()
V[1:5,
]
type(V)
typeof(v)
typeof(V)
dim(iris)
sum(!V[, 'num2'] | !V[, 'num1'])
# 1) Load iris.csv, use the str() function to get a first look at the data
#    check if any columns need to be coerced into a different data type
iris = read.csv('iris.csv')
# 5) Filter iris to contain only observations that do not violate any of the rules
iris = subset(iris, V).dropna()
# 5) Filter iris to contain only observations that do not violate any of the rules
iris = na.omit(subset(iris, V))
dim(iris)
# 1) Load iris.csv, use the str() function to get a first look at the data
#    check if any columns need to be coerced into a different data type
iris = read.csv('iris.csv')
# 5) Filter iris to contain only observations that do not violate any of the rules
iris_filtered = na.omit(subset(iris, V))
View(iris_filtered)
View(iris_filtered)
hist(iris_filtered$Petal.Length, breaks=30, xlab = "Petal Length")
# 5) Filter iris to contain only observations that do not violate any of the rules
iris_filtered = na.omit(subset(iris, V))
hist(iris_filtered$Petal.Length, breaks=30, xlab = "Petal Length")
hist(iris_filtered$Sepal.Width, breaks=30, xlab = "Sepal Width")
# 3) create a simple ruleset that contains the rules that the columns of the dataframe should obey
# Sepal.width should not have values over 10, Petal.Length cannot be negative:
E = editset(c("Sepal.Width > 10", "Petal.Length < 0"))
V = violatedEdits(E, iris)
# 4) number of observations that violate each of the rules
# V[, 'num1'] gives which rows violated Sepal.Width > 10 (False if violated)
sum(!V[,"num1"])
#  V[, 'num2'] gives which rows violated Petal.Length < 0 (False if violated)
sum(!V[, 'num2'])
# 5) Filter iris to contain only observations that do not violate any of the rules
iris_filtered = na.omit(subset(iris, V))
dim(iris)
dim(iris_filtered)
# 5) Filter iris to contain only observations that do not violate any of the rules
iris_filtered = na.omit(subset(iris, !V[, 'num1'] | !V[, 'num2']))
# 5) Filter iris to contain only observations that do not violate any of the rules
iris_filtered = na.omit(subset(iris, V[, 'num1'] | V[, 'num2']))
dim(iris_filtered)
dim(iris_filtered)
# 5) Filter iris to contain only observations that do not violate any of the rules
iris_filtered = na.omit(subset(iris, V[, 'num1'] | V[, 'num2']))
# 5) Filter iris to contain only observations that do not violate any of the rules
iris_filtered = na.omit(subset(iris, (V[, 'num1'] | V[, 'num2'])))
dim(iris_filtered)
# 5) Filter iris to contain only observations that do not violate any of the rules
sum(!V[,"num1"] | !V[, 'num2'])
# 4) number of observations that violate each of the rules
# V[, 'num1'] gives which rows violated Sepal.Width > 10 (False if violated)
sum(V[,"num1"])
#  V[, 'num2'] gives which rows violated Petal.Length < 0 (False if violated)
sum(V[, 'num2'])
V[,'num1
']
V[1:10,'num1']
# 3) create a simple ruleset that contains the rules that the columns of the dataframe should obey
# Sepal.width should not have values over 10, Petal.Length cannot be negative:
E = editset(c("Sepal.Width > 10", "Petal.Length < 0"))
V = violatedEdits(E, iris)
# 4) number of observations that violate each of the rules
# V[, 'num1'] gives which rows violated Sepal.Width > 10 (False if violated)
sum(V[,"num1"])
students = c("John", "Paul", "Ringo", "George", "Ravi")
grade = c(85, 92, 93, 86, -5)
age = c(23, "24", 27, 900, 31)
df = data.frame(students, grade, age)
E = editset(c("grade < 0", "age > 150"))
V = violatedEdits(E, df)
#' It tells us, for each row, which rules were violated...
V
df$age = as.numeric(df$age)
df$age
as.numeric(df$age)
#' This didn't convert the values in the data frame, we need to
#' assign it back:
df$age = as.numeric(df$age)
students = c("John", "Paul", "Ringo", "George", "Ravi")
grade = c(85, 92, 93, 86, -5)
age = c(23, "24", 27, 900, 31)
df = data.frame(students, grade, age)
#' First thing we want to do is check data types. Is everything
#' what you expect?
class(df$students)
class(df$grade)
class(df$age)
#' RANT: R saw that one element of *age* was a string. Since
#' vectors/columns can only have one type, it decided to make
#' the entire column a `character` type. Why doesn't it throw
#' an error? Because R...
#' In any case, functions like `as.numeric()`, `as.character()`
#' etc. will help you convert different columns:
df$age
as.numeric(df$age)
#' This didn't convert the values in the data frame, we need to
#' assign it back:
df$age = as.numeric(df$age)
#' That was a simple example, but it comes up all the time!
#' Datasets might include $ signs for prices, or weird formats
#' for dates (check out the `lubridate` library for easy date
#' manipulation). You'll often have to convert types.
#' Next up, let's look for logical inconsistencies. What are
#' the ranges you'd expect for age/grade?
df$age > 150
#' Cool thing about R: `TRUE` counts as 1, and `FALSE` counts as
#' zero. So I can count how many grades are "bad" by summing
#' over the T/F vector.
sum(df$grade < 0 | df$grade > 100)
library(editrules)
E = editset(c("grade < 0", "age > 150"))
V = violatedEdits(E, df)
#' It tells us, for each row, which rules were violated...
V
#' So we can check, say, how many rows violated each rule...
V[,"num1"] | V[,"num2"] #| V[,"num3"]
#  V[, 'num2'] gives which rows violated Petal.Length < 0 (False if violated)
sum(!V[, 'num2'])
# 1) Load iris.csv, use the str() function to get a first look at the data
#    check if any columns need to be coerced into a different data type
iris = read.csv('iris.csv')
# 3) create a simple ruleset that contains the rules that the columns of the dataframe should obey
# Sepal.width should not have values over 10, Petal.Length cannot be negative:
E = editset(c("Sepal.Width > 10", "Petal.Length < 0"))
V = violatedEdits(E, iris)
V
# 5) Filter iris to contain only observations that do not violate any of the rules
sum(!V[,"num1"] | !V[, 'num2'])
sum(!V[,"num1"])
sum(V[, 'num2'])
sum(!V[, 'num2'])
V
# 65
iris_filtered = na.omit(subset(iris, (!V[, 'num1'] | !V[, 'num2'])))
dim(iris_filtered)
# 65
iris_filtered = na.omit(subset(iris, (!V[, 'num1'] & !V[, 'num2'])))
# 65
iris_filtered = na.omit(subset(iris, (!V[, 'num1'] & !V[, 'num2'])))
View(iris_filtered)
View(iris_filtered)
# 65
iris_filtered = na.omit(subset(iris, !V[, 'num1']))
dim(iris_filtered)
View(iris_filtered)
View(iris_filtered)
# 65
iris_filtered = na.omit(subset(iris, V[, 'num1']))
View(iris_filtered)
View(iris_filtered)
iris_filtered = na.omit(subset(iris, V[, 'num2']))
dim(iris_filtered)
# 65
iris_filtered = na.omit(subset(iris, V[, 'num1']))
iris_filtered = na.omit(subset(iris_filtered, V[, 'num2']))
dim(iris_filtered)
iris_filtered = na.omit(subset(iris, V[, 'num1'] | V[,'num2']))
dim(iris_filtered)
V
iris_fultered = na.omit(subset(iris, V))
iris_filtered = na.omit(subset(iris, V))
dim(iris_filtered)
# 65
iris_filtered = na.omit(subset(iris, V[, 'num1']))
iris_filtered = na.omit(subset(iris_filtered, V[, 'num2']))
dim(iris_filtered)
iris_filtered = na.omit(subset(iris, V[, 'num1'] | V[,'num2']))
dim(iris_filtered)
# 3) create a simple ruleset that contains the rules that the columns of the dataframe should obey
# Sepal.width should not have values over 10, Petal.Length cannot be negative:
E = editset(c("Sepal.Width < 10", "Petal.Length > 0"))
V = violatedEdits(E, iris)
# 1) Load iris.csv, use the str() function to get a first look at the data
#    check if any columns need to be coerced into a different data type
iris = read.csv('iris.csv')
str(iris)
# 3) create a simple ruleset that contains the rules that the columns of the dataframe should obey
# Sepal.width should not have values over 10, Petal.Length cannot be negative:
E = editset(c("Sepal.Width < 10", "Petal.Length > 0"))
V = violatedEdits(E, iris)
# 4) number of observations that violate each of the rules
# V[, 'num1'] gives which rows violated Sepal.Width > 10 (False if violated)
sum(V[,"num1"])
#  V[, 'num2'] gives which rows violated Petal.Length < 0 (False if violated)
sum(V[, 'num2'])
# 5) Filter iris to contain only observations that do not violate any of the rules
sum(V[,"num1"] | V[, 'num2'])
iris_filtered = na.omit(subset(iris, !V[, 'num1'] & !V[,'num2']))
dim(iris_filtered)
V
hist(iris_filtered$Sepal.Width, breaks=30, xlab = "Sepal Width")
hist(iris_filtered$Petal.Length, breaks=30, xlab = "Petal Length")
hist(iris$Sepal.Width, breaks=30, xlab = "Sepal Width")
hist(iris$Petal.Length, breaks=30, xlab = "Petal Length")
# 4) number of observations that violate each of the rules
# V[, 'num1'] gives which rows violated Sepal.Width > 10
sum(V[,"num1"])
#  V[, 'num2'] gives which rows violated Petal.Length < 0
sum(V[, 'num2'])
# 5) Filter iris to contain only observations that do not violate any of the rules
iris_filtered = na.omit(subset(iris, !V[, 'num1'] & !V[,'num2']))
dim(iris_filtered)

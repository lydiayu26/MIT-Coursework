{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AnyZKqH6PDzt"
   },
   "outputs": [],
   "source": [
    "!wget http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpqyEARQHS9E"
   },
   "source": [
    "Specify the location of your CUB_200_2011.tgz file to extract it. \n",
    "\n",
    "If you manually uploaded it to drive, click on the folder icon on the left, you will slidebar show up. There will be three icons appear, click on the third one to grant this Google collab notebook to your drive to access your file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg7orVtWPFJO"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "tar = tarfile.open(\"drive/MyDrive/CUB_200_2011.tgz\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRms4cbKK08s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vu-VVkCPJrJa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utSWS-1RUlZ5"
   },
   "outputs": [],
   "source": [
    "# These are the metadata of all bird species and images\n",
    "#path to dataset\n",
    "data_path = 'CUB_200_2011/'\n",
    "# aggregate datasets\n",
    "df_images = pd.read_csv(data_path+'images.txt', \n",
    "                        sep = ' ',header = None, \n",
    "                        names = ['img_num','img'])\n",
    "df_labels = pd.read_csv(data_path+'image_class_labels.txt', \n",
    "                        sep = ' ',header = None, \n",
    "                        names = ['img_num','class_id'])\n",
    "df_classes = pd.read_csv(data_path+'classes.txt', \n",
    "                         sep = ' ', header = None, \n",
    "                         names = ['class_id','bird_class'])\n",
    "df_split = pd.read_csv(data_path +'train_test_split.txt', \n",
    "                       sep = ' ', header = None, \n",
    "                       names = ['img_num','dataset'])\n",
    "df = pd.merge(df_images, df_labels, on = 'img_num', how = 'inner')\n",
    "df = pd.merge(df, df_classes, on = 'class_id',how = 'inner')\n",
    "df = pd.merge(df, df_split, on = 'img_num',how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCTozGuWS-KN"
   },
   "outputs": [],
   "source": [
    "# Delete unncessary dataframes to save RAM and storage space\n",
    "del df_images, df_labels, df_classes, df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyLaLMMpKz7j"
   },
   "outputs": [],
   "source": [
    "# Define all classes that belong to sparrow\n",
    "sparrow_class = ['113.Baird_Sparrow', '114.Black_throated_Sparrow', \n",
    "                 '115.Brewer_Sparrow', '116.Chipping_Sparrow', '117.Clay_colored_Sparrow',\n",
    "                 '118.House_Sparrow', '119.Field_Sparrow', '120.Fox_Sparrow',\n",
    "                 '121.Grasshopper_Sparrow', '122.Harris_Sparrow', '123.Henslow_Sparrow',\n",
    "                 '124.Le_Conte_Sparrow', '125.Lincoln_Sparrow',\n",
    "                 '126.Nelson_Sharp_tailed_Sparrow', '127.Savannah_Sparrow',\n",
    "                 '128.Seaside_Sparrow', '129.Song_Sparrow', '130.Tree_Sparrow',\n",
    "                 '131.Vesper_Sparrow', '132.White_crowned_Sparrow', '133.White_throated_Sparrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSMn8xc7LAWF"
   },
   "outputs": [],
   "source": [
    "# Define the output label: Is this a sparrow or not?\n",
    "df['OUTPUT_LABEL'] = (df.bird_class.isin(sparrow_class)).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at0b33osInqq"
   },
   "source": [
    "# Problem 1, Part a: Split the data into 70% train and 30% test using random seed 42, write a function to calculate the percentage of sparrows in train and in test. Report the percentages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suol1TO_LBd8"
   },
   "outputs": [],
   "source": [
    "df = df.sample(n = len(df), random_state = 42)\n",
    "\n",
    "############## Fill in the following lines #############\n",
    "df_train_all = \n",
    "df_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8woFw697LDcT",
    "outputId": "828a4c93-af63-4d6c-caeb-95edb3526db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train all 0.145\n",
      "valid 0.150\n"
     ]
    }
   ],
   "source": [
    "############## Fill in the following lines #############\n",
    "def calc_counts(y):\n",
    "    return \n",
    "\n",
    "print('train all %.3f'%calc_counts(df_train_all.OUTPUT_LABEL))\n",
    "print('test %.3f'%calc_counts(df_test.OUTPUT_LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_njeodkLEVq"
   },
   "outputs": [],
   "source": [
    "# List of all sparrow images directory\n",
    "sparrow_imgs = df_train_all.loc[df_train_all.OUTPUT_LABEL == 1,'img'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y00jBuuOLFm-"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqhq7axZKDHl"
   },
   "source": [
    "# Problem 1, Part b: Define two data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmSUIjJsMxS6"
   },
   "outputs": [],
   "source": [
    "!mkdir CUB_200_2011/images/aug_sparrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3mrPaGW6LIAA"
   },
   "outputs": [],
   "source": [
    "# if you still encounter errors here, make a directory called aug_sparrows first in the images folder\n",
    "for bird_img in tqdm(sparrow_imgs):\n",
    "  img = load_img(data_path + 'images/' + bird_img)\n",
    "  img = img_to_array(img)\n",
    "  img = np.expand_dims(img, axis = 0)\n",
    "  \n",
    "  ############## Fill in the following lines #############\n",
    "  aug = \n",
    "  \n",
    "  img_gen = aug.flow(img, batch_size = 1, \n",
    "                     save_to_dir = data_path + 'images/aug_sparrows',\n",
    "                     save_prefix = 'image', \n",
    "                     save_format = 'jpg')\n",
    "  \n",
    "  total = 0\n",
    "  for image in img_gen:\n",
    "    total += 1\n",
    "    if total == 2:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWtdpu6xLJb1"
   },
   "outputs": [],
   "source": [
    "# Aggregate augmented datasets and available training dataset\n",
    "from os import listdir\n",
    "sparrow_aug_files = ['aug_sparrows/'+ a for a in listdir(data_path+'images/aug_sparrows/') if a.endswith('.jpg')]\n",
    "df_aug = pd.DataFrame({'img':sparrow_aug_files, 'OUTPUT_LABEL': [1]*len(sparrow_aug_files) })\n",
    "df_c = pd.concat([df_train_all[['img','OUTPUT_LABEL']],df_aug],\n",
    "                 axis = 0, ignore_index = True, sort = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3I0p8hYLZXU"
   },
   "outputs": [],
   "source": [
    "# Balance the data with a 1:1 ratio between sparrow and non-sparrow\n",
    "rows_pos = df_c.OUTPUT_LABEL == 1\n",
    "df_pos = df_c.loc[rows_pos]\n",
    "df_neg = df_c.loc[~rows_pos]\n",
    "n= min([len(df_pos), len(df_neg)])\n",
    "df_train = pd.concat([df_pos.sample(n = n,random_state = 42), \n",
    "                      df_neg.sample(n = n, random_state = 42)], \n",
    "                     axis = 0)\n",
    "df_train = df_train.sample(frac = 1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccGmtoVBS3_0"
   },
   "outputs": [],
   "source": [
    "del df, df_train_all, df_aug, df_c, df_pos, df_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XK-DhkqjWA8p"
   },
   "outputs": [],
   "source": [
    "# To not crash our RAM, randomly only select half of the samples in train and test\n",
    "df_train = df_train.sample(frac = 0.5, random_state = 42)\n",
    "df_test = df_test.sample(frac = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtKR8kmwMZaB"
   },
   "source": [
    "# Problem 1, Part c: Standarize input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uunITk36LaRt"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "def load_imgs(df):\n",
    "    imgs = np.ndarray(shape = (len(df), IMG_SIZE, IMG_SIZE,3), dtype = np.float32)\n",
    "    for ii in range(len(df)):\n",
    "        file = df.img.values[ii]\n",
    "\n",
    "        ############## Fill in the following lines #############\n",
    "        img = load_img(data_path+'images/'+file .... )\n",
    "\n",
    "        ############## Fill in the following lines #############\n",
    "        # Normalize pixel value to [0, 1] using img_to_array, then divide by 255\n",
    "        img = \n",
    "        imgs[ii] = img\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kbjPOUNLzjI"
   },
   "outputs": [],
   "source": [
    "# Will take a long time and a lot of RAM\n",
    "X_train = load_imgs(df_train)\n",
    "X_test = load_imgs(df_test)\n",
    "y_train = df_train.OUTPUT_LABEL.values\n",
    "y_test = df_test.OUTPUT_LABEL.values\n",
    "\n",
    "# reshape\n",
    "X_train = X_train.reshape(X_train.shape[0], IMG_SIZE,IMG_SIZE, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], IMG_SIZE,IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XNThQyWeL2gh"
   },
   "outputs": [],
   "source": [
    "ii = 3\n",
    "plt.imshow(X_train[ii])\n",
    "plt.title(df_train.img.iloc[ii])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uncfiUxeMhCL"
   },
   "source": [
    "# Problem 1, Part d: Build Your Own Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O72u3wRVL3te"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5), \n",
    "                 activation = 'relu', \n",
    "                 input_shape = X_train.shape[1:]))\n",
    "\n",
    "############## Fill in the following lines #############\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3l3JpNQPgez"
   },
   "source": [
    "# Problem 1, Part e: Define training loss and optimizer, observe loss behavior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNfNiUGFL5cd"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "                loss = ,\n",
    "                optimizer = ,\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1EKuP9NwL64c"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size = 64, epochs= 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GiMIjhNcL9Ge"
   },
   "outputs": [],
   "source": [
    "y_train_preds = model.predict_proba(X_train,verbose = 1)\n",
    "y_test_preds = model.predict_proba(X_test,verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRtlp6DEQIec"
   },
   "source": [
    "# Problem 1, Part f: Report AUC and accuracy for full train/test, and report accuracy for each individual sparrow class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E37cHFrfMMVW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework 3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
